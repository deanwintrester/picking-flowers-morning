{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e280605",
   "metadata": {},
   "source": [
    "# nni模型压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846aa61",
   "metadata": {},
   "source": [
    "## 创建模型 并进行预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e8a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "\n",
    "from scripts.compression_mnist_model import TorchModel, trainer, evaluator, device\n",
    "\n",
    "# define the model\n",
    "model = TorchModel().to(device)\n",
    "\n",
    "# show the model structure, note that pruner will wrap the model layer.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c82f45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average test loss: 0.8338, Accuracy: 8061/10000 (81%)\n",
      "Average test loss: 0.2623, Accuracy: 9190/10000 (92%)\n",
      "Average test loss: 0.1851, Accuracy: 9429/10000 (94%)\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer and criterion for pre-training\n",
    "\n",
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "criterion = F.nll_loss\n",
    "\n",
    "# pre-train and evaluate the model on MNIST dataset\n",
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)\n",
    "    evaluator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3894c6",
   "metadata": {},
   "source": [
    "### 原始模型速度测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7b0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model - Elapsed Time :  0.0036008358001708984\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "model(torch.rand(128, 1, 28, 28).to(device))\n",
    "print('Original Model - Elapsed Time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c10b03",
   "metadata": {},
   "source": [
    "## 模型剪枝\n",
    "·使用 L1NormPruner 对模型进行剪枝 并 生成掩码\n",
    "·两个输入参数:\n",
    "    config_list : 设置修剪类型\n",
    "    model : 待修剪的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ddd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [{\n",
    "    'sparsity_per_layer': 0.5,\n",
    "    'op_types': ['Linear', 'Conv2d']\n",
    "}, {\n",
    "    'exclude': True,\n",
    "    'op_names': ['fc3']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d536974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.compression.pytorch.pruning import L1NormPruner\n",
    "pruner = L1NormPruner(model, config_list)\n",
    "\n",
    "# show the wrapped model structure, `PrunerModuleWrapper` have wrapped the layers that configured in the config_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "438ae8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1  sparsity :  0.5\n",
      "conv2  sparsity :  0.5\n",
      "fc1  sparsity :  0.5\n",
      "fc2  sparsity :  0.5\n"
     ]
    }
   ],
   "source": [
    "# compress the model and generate the masks\n",
    "_, masks = pruner.compress()\n",
    "# show the masks sparsity\n",
    "for name, mask in masks.items():\n",
    "    print(name, ' sparsity : ', '{:.2}'.format(mask['weight'].sum() / mask['weight'].numel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0af3ee",
   "metadata": {},
   "source": [
    "### 输出的掩码 masks 并未真正的减小模型，只是置零，参数仍需计算\n",
    "需要 nni 的 ModelSpeedup 使模型真正变小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18258099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-01-31 10:10:40] \u001b[32mstart to speedup the model\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32minfer module masks...\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for conv1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for relu1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for pool1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for conv2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for relu2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for pool2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for .aten::flatten.11\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for fc1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for relu3\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for fc2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for relu4\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for fc3\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate mask for .aten::log_softmax.12\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the .aten::log_softmax.12\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the fc3\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the relu4\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the fc2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the relu3\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the fc1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the .aten::flatten.11\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the pool2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the relu2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the conv2\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the pool1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the relu1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mUpdate the indirect sparsity for the conv1\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mresolve the mask conflict\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace compressed modules...\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: conv1, op_type: Conv2d)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: relu1, op_type: ReLU)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: pool1, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: conv2, op_type: Conv2d)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: relu2, op_type: ReLU)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: pool2, op_type: MaxPool2d)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: fc1, op_type: Linear)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace linear with new in_features: 128, out_features: 60\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: relu3, op_type: ReLU)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: fc2, op_type: Linear)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace linear with new in_features: 60, out_features: 42\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: relu4, op_type: ReLU)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace module (name: fc3, op_type: Linear)\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mreplace linear with new in_features: 42, out_features: 10\u001b[0m\n",
      "[2023-01-31 10:10:41] \u001b[32mspeedup done\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda\\envs\\any\\lib\\site-packages\\nni\\compression\\pytorch\\speedup\\compressor.py:305: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  if last_output.grad is not None and tin.grad is not None:\n",
      "D:\\ProgramFiles\\Anaconda\\envs\\any\\lib\\site-packages\\nni\\compression\\pytorch\\speedup\\compressor.py:307: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:485.)\n",
      "  elif last_output.grad is None:\n"
     ]
    }
   ],
   "source": [
    "# need to unwrap the model, if the model is wrapped before speedup\n",
    "pruner._unwrap_model()\n",
    "\n",
    "# speedup the model\n",
    "from nni.compression.pytorch.speedup import ModelSpeedup\n",
    "\n",
    "ModelSpeedup(model, torch.rand(3, 1, 28, 28).to(device), masks).speedup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0886788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchModel(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=128, out_features=60, bias=True)\n",
      "  (fc2): Linear(in_features=60, out_features=42, bias=True)\n",
      "  (fc3): Linear(in_features=42, out_features=10, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (relu2): ReLU()\n",
      "  (relu3): ReLU()\n",
      "  (relu4): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61a71a",
   "metadata": {},
   "source": [
    "### 加速后速度测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80177ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup Model - Elapsed Time :  0.003857135772705078\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model(torch.rand(128, 1, 28, 28).to(device))\n",
    "print('Speedup Model - Elapsed Time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17135d9",
   "metadata": {},
   "source": [
    "## 微调剪枝后的模型\n",
    "微调模型前，需要重新生成 optimizer，（加速过程中进行了层替换，原来的 optimizer 已不适用新模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bbad739",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(model.parameters(), 1e-2)\n",
    "for epoch in range(3):\n",
    "    trainer(model, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef4e32cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup Model - Elapsed Time :  0.003574848175048828\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model(torch.rand(128, 1, 28, 28).to(device))\n",
    "print('Speedup Model - Elapsed Time : ', time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (any)",
   "language": "python",
   "name": "any"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
